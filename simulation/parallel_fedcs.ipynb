{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all needed packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Get the absolute path of the src directory\n",
    "src_path = os.path.abspath('../src')\n",
    "\n",
    "# Add src_path to sys.path\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    \n",
    "import fl\n",
    "from client import Client, ClientResources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Tensorboard notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 22:36:41.019330: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cdb8bbba5b25b72e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cdb8bbba5b25b72e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir=\"./logs/federated_learning\")\n",
    "\n",
    "# Load TensorBoard extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Start TensorBoard\n",
    "%tensorboard --logdir=."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 48000, Validation dataset size: 12000, Test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "\n",
    "# Define transformations for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to range [-1, 1]\n",
    "])\n",
    "\n",
    "# Download and load MNIST dataset\n",
    "mnist_full = datasets.MNIST(root=\"../data\", train=True, transform=transform, download=True)\n",
    "mnist_test = datasets.MNIST(root=\"../data\", train=False, transform=transform, download=True)\n",
    "\n",
    "# Split training data into training and validation sets\n",
    "train_size = int(0.8 * len(mnist_full))  # 80% for training\n",
    "val_size = len(mnist_full) - train_size  # 20% for validation\n",
    "train_dataset, val_dataset = random_split(mnist_full, [train_size, val_size])\n",
    "\n",
    "# Extract indices from Subset objects\n",
    "train_indices = train_dataset.indices  # List of training indices\n",
    "val_indices = val_dataset.indices      # List of validation indices\n",
    "\n",
    "# Create training and validation MNIST datasets\n",
    "mnist_train = datasets.MNIST(root=\"../data\", train=True, transform=transform, download=False)\n",
    "mnist_val = datasets.MNIST(root=\"../data\", train=True, transform=transform, download=False)\n",
    "\n",
    "# Filter datasets by indices\n",
    "mnist_train.data = mnist_train.data[torch.tensor(train_indices)]\n",
    "mnist_train.targets = mnist_train.targets[torch.tensor(train_indices)]\n",
    "mnist_val.data = mnist_val.data[torch.tensor(val_indices)]\n",
    "mnist_val.targets = mnist_val.targets[torch.tensor(val_indices)]\n",
    "\n",
    "# Create DataLoaders for training and validation datasets\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(mnist_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Train dataset size: {len(mnist_train)}, Validation dataset size: {len(mnist_val)}, Test dataset size: {len(mnist_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hp = {\n",
    "    \"run_id\": \"delta\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_clients\": 4,\n",
    "    \"num_rounds\": 2,\n",
    "    \"num_classes\": 10,\n",
    "    \"classes_per_client\": 8,\n",
    "    \"epochs\": 3,    # number of epochs to train in each round\n",
    "    \"split\": \"RANDOM\"   # [\"RANDOM\", \"NONIID\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset: non-IID / Random\n",
    "\n",
    "### Create client train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated 4 clients, each with 12000 training samples.\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Number of clients and non-IID split\n",
    "num_clients = hp[\"num_clients\"]\n",
    "batch_size = hp[\"batch_size\"]\n",
    "train_data_size = len(mnist_train) // num_clients\n",
    "val_data_size = len(mnist_val) // num_clients\n",
    "\n",
    "\n",
    "if hp[\"split\"] == \"NONIID\":\n",
    "    classes_per_client = hp[\"classes_per_client\"]\n",
    "    num_classes = hp[\"num_classes\"]\n",
    "\n",
    "    # Create indices for each class\n",
    "    train_class_indices = {i: np.where(np.array(mnist_train.targets) == i)[0] for i in range(num_classes)}\n",
    "    val_class_indices = {i: np.where(np.array(mnist_val.targets) == i)[0] for i in range(num_classes)}\n",
    "\n",
    "    # Assign 2 classes per client\n",
    "    train_indices = []\n",
    "    val_indices = []\n",
    "    for client_id in range(num_clients):\n",
    "        chosen_classes = np.random.choice(num_classes, classes_per_client, replace=False)\n",
    "        train_client_idx = []\n",
    "        val_client_idx = []\n",
    "        for cls in chosen_classes:\n",
    "            train_cls_size = len(train_class_indices[cls]) // (num_clients // classes_per_client)\n",
    "            train_cls_idx = np.random.choice(train_class_indices[cls], train_cls_size, replace=False)\n",
    "            train_client_idx.extend(train_cls_idx)\n",
    "            val_cls_size = len(val_class_indices[cls]) // (num_clients // classes_per_client)\n",
    "            val_cls_idx = np.random.choice(val_class_indices[cls], val_cls_size, replace=False)\n",
    "            val_client_idx.extend(val_cls_idx)\n",
    "            # Remove assigned indices to avoid duplication\n",
    "            train_class_indices[cls] = np.setdiff1d(train_class_indices[cls], train_cls_idx)\n",
    "            val_class_indices[cls] = np.setdiff1d(val_class_indices[cls], val_cls_idx)\n",
    "\n",
    "        train_indices.append(train_client_idx)\n",
    "        val_indices.append(val_client_idx)\n",
    "\n",
    "    # Create datasets and DataLoaders for each client\n",
    "    train_datasets = [Subset(mnist_train, indices) for indices in train_indices]\n",
    "    train_loaders = [DataLoader(ds, batch_size=batch_size, shuffle=True) for ds in train_datasets]\n",
    "    val_datasets = [Subset(mnist_val, indices) for indices in val_indices]\n",
    "    val_loaders = [DataLoader(ds, batch_size=batch_size, shuffle=True) for ds in val_datasets]\n",
    "\n",
    "    # Example: Check the distribution of classes for a specific client\n",
    "    train_sample_classes = [mnist_train.targets[idx].item() for idx in train_indices[0]]\n",
    "    print(\"Client 0 has classes:\", set(train_sample_classes))\n",
    "\n",
    "else:\n",
    "    \n",
    "    # Split the training data into smaller datasets for each client\n",
    "    train_datasets = random_split(mnist_train, [train_data_size] * num_clients)\n",
    "    train_loaders = [DataLoader(ds, batch_size=batch_size, shuffle=True) for ds in train_datasets]\n",
    "\n",
    "    val_datasets = random_split(mnist_train, [train_data_size] * num_clients)\n",
    "    val_loaders = [DataLoader(ds, batch_size=batch_size, shuffle=True) for ds in train_datasets]\n",
    "\n",
    "# Test DataLoader for evaluation\n",
    "print(f\"Simulated {num_clients} clients, each with {train_data_size} training samples.\")\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataset.Subset at 0x7fc033fbe1d0>,\n",
       " <torch.utils.data.dataset.Subset at 0x7fc04a3c6dd0>,\n",
       " <torch.utils.data.dataset.Subset at 0x7fc0370c3a60>,\n",
       " <torch.utils.data.dataset.Subset at 0x7fc0370c3a90>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in val_loaders[0]:  # Example for the first client\n",
    "    print(inputs.shape, labels.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up and initialize the Global Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialization: Instantiate the global model (server)\n",
    "model = fl.create_model()\n",
    "global_model = model\n",
    "print(global_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client training loop\n",
    "\n",
    "## TODO: Delegate this to the fl ml utils file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a training loop that is run on a client for a number of epochs\n",
    "def train_model(model, train_loader, hp, epochs=1):\n",
    "    \n",
    "    lr = hp[\"learning_rate\"]\n",
    "\n",
    "    # 3. Distribution: Create a copy of the global model\n",
    "    local_model = fl.create_model()\n",
    "    local_model.load_state_dict(model.state_dict())\n",
    "    \n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(local_model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training loop\n",
    "    local_model.train()\n",
    "    total_loss = 0  # Initialize total loss\n",
    "    num_batches = 0  # Initialize batch counter\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = local_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "    \n",
    "    # Calculate average training loss\n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "    return local_model.state_dict(), avg_loss  # Return updated model parameters and average loss\n",
    "\n",
    "\n",
    "# # Validation function\n",
    "# def validate_model(model, val_loader):\n",
    "#     model.eval()\n",
    "#     criterion = nn.CrossEntropyLoss()  # Define the loss function\n",
    "#     total_loss = 0\n",
    "#     num_batches = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in val_loader:\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels) #F.cross_entropy(outputs, labels, reduction='sum')  # Compute loss for the batch\n",
    "#             total_loss += loss.item()\n",
    "#             num_batches += 1\n",
    "    \n",
    "#     avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "#     return avg_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clients\n",
    "\n",
    "### Client Creation\n",
    "We create clients with various resources, in which we take into account, speed, availability, battery level, bandwidth, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create client instances\n",
    "\n",
    "# Example of a client's resources\n",
    "# resources = ClientResources(\n",
    "#     speed_factor=1.5,\n",
    "#     battery_level=80,\n",
    "#     bandwidth=10.0,\n",
    "#     dataset_size=1000,\n",
    "#     CPU_available=True,\n",
    "#     CPU_memory_availability=64.0,\n",
    "#     GPU_available=True,\n",
    "#     GPU_memory_availability=16.0,\n",
    "# )\n",
    "\n",
    "clients = []\n",
    "for i in range(num_clients):\n",
    "    mock_resources = ClientResources.generate_random((len(train_datasets[i]), len(train_datasets[i])))\n",
    "\n",
    "    new_client = Client(id=i, resources=mock_resources, dataset=train_datasets[i], dataloader=train_loaders[i], val_loader=val_loaders[i])\n",
    "    clients.append(new_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_selection_with_constraints(clients, deadline):\n",
    "    \"\"\"\n",
    "    Select clients based on their resource availability and time constraints.\n",
    "    Returns a list of client objects.\n",
    "    \n",
    "    Args:\n",
    "        clients (list): List of Client objects.\n",
    "        deadline (float): Maximum time allowed for training and upload.\n",
    "    \n",
    "    Returns:\n",
    "        List of selected Client objects.\n",
    "    \"\"\"\n",
    "    # Calculate update times for all clients\n",
    "    client_times = [\n",
    "        (client, client.resources.dataset_size / client.resources.speed_factor)  # (Client object, update_time)\n",
    "        for client in clients\n",
    "    ]\n",
    "    \n",
    "    # Sort clients by their update time\n",
    "    client_times.sort(key=lambda x: x[1])\n",
    "\n",
    "    selected_clients = []\n",
    "    total_time = 0\n",
    "\n",
    "    # Select clients within the deadline\n",
    "    for client, update_time in client_times:\n",
    "        if total_time + update_time <= deadline:\n",
    "            selected_clients.append(client)\n",
    "            total_time += update_time\n",
    "        else:\n",
    "            break  # Stop once adding a client exceeds the deadline\n",
    "\n",
    "    return selected_clients\n",
    "\n",
    "\n",
    "\n",
    "def select_indices(n, k):\n",
    "    return random.sample(range(n), k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(global_model, val_loaders):\n",
    "    \"\"\"\n",
    "    Evaluate the global model on multiple client validation sets.\n",
    "\n",
    "    Args:\n",
    "        global_model (nn.Module): The global model to evaluate.\n",
    "        val_loaders (list): List of DataLoaders for each client's validation set.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Weighted average validation loss and accuracy.\n",
    "    \"\"\"\n",
    "    global_model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_loader in val_loaders:\n",
    "            client_loss = 0.0\n",
    "            client_correct = 0\n",
    "            client_samples = 0\n",
    "\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = global_model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                client_loss += loss.item() * len(labels)  # Accumulate loss weighted by batch size\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                client_correct += (preds == labels).sum().item()  # Count correct predictions\n",
    "                client_samples += len(labels)  # Track number of samples\n",
    "\n",
    "            # Accumulate client metrics into global metrics\n",
    "            total_loss += client_loss\n",
    "            total_correct += client_correct\n",
    "            total_samples += client_samples\n",
    "\n",
    "    # Compute global averages\n",
    "    avg_loss = total_loss / total_samples if total_samples > 0 else 0.0\n",
    "    avg_accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "    return avg_loss, avg_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Federated Learning Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function for client training\n",
    "def train_client_parallel(client, global_model, epochs=1):\n",
    "    print(f\"\\nTraining client {client.id} with resources {client.resources}\")\n",
    "    return client.id, client.train(global_model, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: False\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This took me 2 mins to run\n",
    "Simulate Federated Learning\n",
    "A learning round consists of all clients training their local models and then aggregating the updates\n",
    "\"\"\"\n",
    "from datetime import datetime\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Generate a unique log directory based on the current time\n",
    "run_number = datetime.now().strftime('%m-%d_%H-%M')  # Month-Day_Hour-Minute\n",
    "log_dir = f\"./logs/{hp['run_id']}/run_{run_number}\"  # Use a timestamp to distinguish runs\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "# Log hyperparameters as text\n",
    "hyperparams_text = \"\\n\".join([f\"{key}: {value}\" for key, value in hp.items()])\n",
    "\n",
    "# Start time measurement\n",
    "start_time = time.time()\n",
    "\n",
    "# Federated Learning with FedCS Client Selection\n",
    "num_rounds = hp[\"num_rounds\"]\n",
    "epochs = hp[\"epochs\"]\n",
    "round_deadline = np.inf  # Example round deadline (in ARBITRARY time units)\n",
    "\n",
    "assert num_clients == len(train_loaders)\n",
    "print(\"GPU available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Conduct federated learning rounds\n",
    "# for round_num in range(num_rounds):\n",
    "#     print(f\"Round {round_num + 1}\")\n",
    "    \n",
    "#     # 2. Resource Request\n",
    "#     k = random.randint(1, num_clients)\n",
    "#     resource_requested_clients = select_indices(num_clients, k)\n",
    "#     print(f\"-- Resource requested from {len(resource_requested_clients)} clients\")\n",
    "\n",
    "#     # 3. Client Selection: Collect client updates\n",
    "#     # TODO: Client ressources\n",
    "#     selected_train_clients = client_selection_with_constraints([clients[i] for i in resource_requested_clients], round_deadline)\n",
    "#     print(f\"-- Filtered to have {len(selected_train_clients)} remaining clients\")\n",
    "\n",
    "#     client_states = []\n",
    "#     round_train_loss = 0  # Initialize round loss\n",
    "#     round_val_loss = 0  # Initialize round loss\n",
    "#     num_batches = 0  # Initialize batch counter\n",
    "\n",
    "\n",
    "#     # Parallelize client training\n",
    "#     client_states = []\n",
    "#     with ThreadPoolExecutor(max_workers=len(clients)) as executor:\n",
    "#         futures = {executor.submit(train_client_parallel, client, global_model, 1): client for client in clients}\n",
    "        \n",
    "#         for future in as_completed(futures):\n",
    "#             client_id, client_state = future.result()\n",
    "#             print(f\"Client {client_id} completed training.\")\n",
    "#             client_states.append(client_state)\n",
    "            \n",
    "#     # 6. Aggregation: Aggregate updates using Federated Averaging\n",
    "#     new_global_state = fl.federated_averaging(global_model, client_states)  \n",
    "#     global_model.load_state_dict(new_global_state)\n",
    "#     print(f\"Global model updated for round {round_num + 1}\")\n",
    "\n",
    "#     # avg_round_val_loss = round_val_loss / num_batches if num_batches > 0 else 0\n",
    "#     # writer.add_scalar(\"Metrics/Validation loss\", avg_round_val_loss, round_num + 1)\n",
    "#     # print(f\"Validation loss after round {round_num + 1}: {avg_round_val_loss}\")\n",
    "\n",
    "# # End time measurement\n",
    "# end_time = time.time()\n",
    "\n",
    "# # Print total execution time\n",
    "# print(f\"Total time taken: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "-- Resource requested from 2 clients\n",
      "-- Filtered to have 2 remaining clients\n",
      "\n",
      "Training client 2 with resources ClientResources(speed_factor=1.755834982776784, battery_level=82.5207510132472, bandwidth=83.76747232486069, dataset_size=12000, CPU_available=True, CPU_memory_availability=20.852758641065478, GPU_available=False, GPU_memory_availability=0)\n",
      "\n",
      "Training client 1 with resources ClientResources(speed_factor=1.6026389530755347, battery_level=61.14394697717021, bandwidth=45.310686196441274, dataset_size=12000, CPU_available=True, CPU_memory_availability=9.039496459714954, GPU_available=True, GPU_memory_availability=28.052662035169973)\n",
      "Training round complete in 10.37: seconds\n",
      "Training round complete in 10.38: seconds\n",
      "Client simulated to take 16.62 seconds for training\n",
      "Client 1 completed training.\n",
      "Client simulated to take 18.24 seconds for training\n",
      "Client 2 completed training.\n",
      "Global model updated for round 1\n",
      "Validation Loss: 0.4443, Validation Accuracy: 86.10%\n",
      "Round 2\n",
      "-- Resource requested from 4 clients\n",
      "-- Filtered to have 4 remaining clients\n",
      "\n",
      "Training client 2 with resources ClientResources(speed_factor=1.755834982776784, battery_level=82.5207510132472, bandwidth=83.76747232486069, dataset_size=12000, CPU_available=True, CPU_memory_availability=20.852758641065478, GPU_available=False, GPU_memory_availability=0)\n",
      "\n",
      "Training client 1 with resources ClientResources(speed_factor=1.6026389530755347, battery_level=61.14394697717021, bandwidth=45.310686196441274, dataset_size=12000, CPU_available=True, CPU_memory_availability=9.039496459714954, GPU_available=True, GPU_memory_availability=28.052662035169973)\n",
      "\n",
      "Training client 3 with resources ClientResources(speed_factor=1.5570819523111623, battery_level=66.23470099664416, bandwidth=9.656229511199511, dataset_size=12000, CPU_available=True, CPU_memory_availability=1.3332862567037154, GPU_available=False, GPU_memory_availability=0)\n",
      "\n",
      "Training client 0 with resources ClientResources(speed_factor=1.347213242081761, battery_level=7.201058643320718, bandwidth=18.65650866744064, dataset_size=12000, CPU_available=True, CPU_memory_availability=10.43141833652939, GPU_available=False, GPU_memory_availability=0)\n",
      "Training round complete in 28.84: seconds\n",
      "Training round complete in 28.90: seconds\n",
      "Training round complete in 28.91: seconds\n",
      "Training round complete in 28.92: seconds\n",
      "Client simulated to take 38.96 seconds for training\n",
      "Client 0 completed training.\n",
      "Client simulated to take 45.03 seconds for training\n",
      "Client 3 completed training.\n",
      "Client simulated to take 46.22 seconds for training\n",
      "Client 1 completed training.\n",
      "Client simulated to take 50.75 seconds for training\n",
      "Client 2 completed training.\n",
      "Global model updated for round 2\n",
      "Validation Loss: 0.2692, Validation Accuracy: 92.04%\n"
     ]
    }
   ],
   "source": [
    "# Conduct federated learning rounds\n",
    "for round_num in range(num_rounds):\n",
    "    print(f\"Round {round_num + 1}\")\n",
    "    \n",
    "    # 2. Resource Request\n",
    "    k = random.randint(1, num_clients)\n",
    "    resource_requested_clients = select_indices(num_clients, k)\n",
    "    print(f\"-- Resource requested from {len(resource_requested_clients)} clients\")\n",
    "\n",
    "    # 3. Client Selection: Collect client updates\n",
    "    selected_train_clients = client_selection_with_constraints(\n",
    "        [clients[i] for i in resource_requested_clients], round_deadline\n",
    "    )\n",
    "    print(f\"-- Filtered to have {len(selected_train_clients)} remaining clients\")\n",
    "\n",
    "    client_states = []\n",
    "\n",
    "    # Parallelize client training\n",
    "    with ThreadPoolExecutor(max_workers=len(selected_train_clients)) as executor:\n",
    "        futures = {\n",
    "            executor.submit(train_client_parallel, client, global_model, 1): client\n",
    "            for client in selected_train_clients\n",
    "        }\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            client_id, client_state = future.result()\n",
    "            print(f\"Client {client_id} completed training.\")\n",
    "            client_states.append(client_state)\n",
    "            \n",
    "    # 6. Aggregation: Aggregate updates using Federated Averaging\n",
    "    new_global_state = fl.federated_averaging(global_model, client_states)  \n",
    "    global_model.load_state_dict(new_global_state)\n",
    "    print(f\"Global model updated for round {round_num + 1}\")\n",
    "\n",
    "    # 7. Evaluate on Validation Set\n",
    "    val_loaders = [client.val_loader for client in clients]  # Get all validation loaders\n",
    "    val_loss, val_accuracy = validate_model(global_model, val_loaders)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2%}\")\n",
    "    \n",
    "    # Optional: Log metrics for visualization\n",
    "    writer.add_scalar(\"Metrics/Validation Loss\", val_loss, round_num + 1)\n",
    "    writer.add_scalar(\"Metrics/Validation Accuracy\", val_accuracy, round_num + 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global model accuracy: 92.16%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_accuracy = correct / total\n",
    "    print(f\"Global model accuracy: {test_accuracy:.2%}\")\n",
    "    return test_accuracy\n",
    "    \n",
    "# Evaluate the model on the test dataset\n",
    "test_accuracy = evaluate_model(global_model, test_loader)\n",
    "\n",
    "# End TensorBoard writer\n",
    "final_metrics = {}\n",
    "writer.add_hparams(hp, final_metrics)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global model saved at ./saved_models/global_model_delta_12-02_22-36.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the final model\n",
    "model_save_path = f\"./saved_models/global_model_{hp['run_id']}_{run_number}.pth\"\n",
    "torch.save(global_model.state_dict(), model_save_path)\n",
    "print(f\"Global model saved at {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

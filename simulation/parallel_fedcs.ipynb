{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, sys, os, random, time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset, Subset\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Append the path\n",
    "src_path = os.path.abspath('../src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    \n",
    "import fl\n",
    "from models import *\n",
    "from quantization import *\n",
    "from client import Client, ClientResources\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hp = {\n",
    "    \"run_id\": \"results\",\n",
    "    \"run_number\": \"noniid2_standard_noshared\",\n",
    "    \"num_classes\": 10,  # 10 for MNIST\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_clients\": 100,\n",
    "    \"num_rounds\": 5,\n",
    "    \"epochs\": 5,    # number of epochs to train in each round\n",
    "    \"setup\": \"standard\",    # [\"standard\", \"scalar\", \"kure\", \"mqat\"]\n",
    "    \"split\": \"NONIID\",   # [\"RANDOM\", \"NONIID\"]\n",
    "    \"classes_per_client\": 2,\n",
    "    \"use_client_selection\": True,\n",
    "    \"quantize\": False,\n",
    "    \"lambda_kure\": 1e-4,\n",
    "    \"delta\": 1e-2,\n",
    "    \"shared_fraction\": 0.00,\n",
    "    \"deadline\": 1000.0,\n",
    "    \"cutoff\": 0.67,\n",
    "    \"bit_widths\": [8, 16, 32]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Tensorboard notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 12:45:25.954683: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'%load_ext tensorboard\\n%tensorboard --logdir=.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir=\".\")\n",
    "\"\"\"%load_ext tensorboard\n",
    "%tensorboard --logdir=.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_fraction = hp['shared_fraction']\n",
    "num_clients = hp[\"num_clients\"]\n",
    "batch_size = hp[\"batch_size\"]\n",
    "classes_per_client = hp[\"classes_per_client\"]\n",
    "num_classes = hp[\"num_classes\"]\n",
    "lr = hp[\"learning_rate\"]\n",
    "epochs = hp[\"epochs\"]\n",
    "split = hp[\"split\"]\n",
    "lambda_kure = hp[\"lambda_kure\"]\n",
    "delta = hp[\"delta\"]\n",
    "setup = hp[\"setup\"]\n",
    "use_client_selection = hp[\"use_client_selection\"]\n",
    "quantize = hp[\"quantize\"]\n",
    "bit_widths = hp[\"bit_widths\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 48000, Train Shared dataset size: 0, Validation dataset size: 12000, Test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define transformations for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to range [-1, 1]\n",
    "])\n",
    "\n",
    "# Download and load MNIST dataset\n",
    "mnist_full = datasets.MNIST(root=\"../data\", train=True, transform=transform, download=True)\n",
    "mnist_test = datasets.MNIST(root=\"../data\", train=False, transform=transform, download=True)\n",
    "\n",
    "# Split training data into training and validation sets\n",
    "train_size = int(0.8 * len(mnist_full))  # 80% for training\n",
    "val_size = len(mnist_full) - train_size  # 20% for validation\n",
    "train_dataset, val_dataset = random_split(mnist_full, [train_size, val_size])\n",
    "\n",
    "shared_size = int(len(train_dataset) * shared_fraction)\n",
    "remaining_size = len(train_dataset) - shared_size\n",
    "train_shared_dataset, train_dataset = random_split(train_dataset, [shared_size, remaining_size])\n",
    "\n",
    "# Extract indices from Subset objects\n",
    "train_indices = train_dataset.indices  # List of training indices\n",
    "\n",
    "train_shared_indices = train_shared_dataset.indices if shared_fraction > 0.0 else []  # List of training indices\n",
    "val_indices = val_dataset.indices      # List of validation indices\n",
    "\n",
    "# Create training and validation MNIST datasets\n",
    "mnist_train = datasets.MNIST(root=\"../data\", train=True, transform=transform, download=False)\n",
    "mnist_train_shared = datasets.MNIST(root=\"../data\", train=True, transform=transform, download=False)\n",
    "mnist_val = datasets.MNIST(root=\"../data\", train=True, transform=transform, download=False)\n",
    "\n",
    "# Filter datasets by indices\n",
    "mnist_train.data = mnist_train.data[torch.tensor(train_indices)]\n",
    "mnist_train.targets = mnist_train.targets[torch.tensor(train_indices)]\n",
    "\n",
    "if shared_fraction > 0.0:\n",
    "    mnist_train_shared.data = mnist_train_shared.data[torch.tensor(train_shared_indices)]\n",
    "    mnist_train_shared.targets = mnist_train_shared.targets[torch.tensor(train_shared_indices)]\n",
    "else:\n",
    "    mnist_train_shared = []\n",
    "\n",
    "mnist_val.data = mnist_val.data[torch.tensor(val_indices)]\n",
    "mnist_val.targets = mnist_val.targets[torch.tensor(val_indices)]\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Train dataset size: {len(mnist_train)}, Train Shared dataset size: {len(mnist_train_shared)}, Validation dataset size: {len(mnist_val)}, Test dataset size: {len(mnist_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset: non-IID / Random\n",
    "\n",
    "### Create client train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated 100 clients, each with 480 training samples, and 12000 validation samples\n",
      "Training Set Label Distribution:\n",
      "Client 0 label distribution: {0: 94, 6: 94}\n",
      "Client 1 label distribution: {9: 96, 7: 99}\n",
      "Client 2 label distribution: {5: 86, 0: 92}\n",
      "Client 3 label distribution: {6: 93, 7: 97}\n",
      "Client 4 label distribution: {2: 95, 1: 109}\n",
      "Client 5 label distribution: {5: 84, 3: 97}\n",
      "Client 6 label distribution: {4: 93, 8: 93}\n",
      "Client 7 label distribution: {3: 95, 2: 93}\n",
      "Client 8 label distribution: {5: 83, 7: 95}\n",
      "Client 9 label distribution: {8: 91, 0: 90}\n",
      "Client 10 label distribution: {8: 89, 6: 91}\n",
      "Client 11 label distribution: {7: 93, 8: 87}\n",
      "Client 12 label distribution: {2: 91, 4: 91}\n",
      "Client 13 label distribution: {2: 89, 8: 85}\n",
      "Client 14 label distribution: {7: 91, 8: 84}\n",
      "Client 15 label distribution: {7: 89, 8: 82}\n",
      "Client 16 label distribution: {7: 88, 3: 93}\n",
      "Client 17 label distribution: {9: 94, 4: 89}\n",
      "Client 18 label distribution: {6: 89, 5: 81}\n",
      "Client 19 label distribution: {3: 92, 4: 87}\n",
      "Client 20 label distribution: {6: 87, 4: 85}\n",
      "Client 21 label distribution: {7: 86, 4: 84}\n",
      "Client 22 label distribution: {7: 84, 2: 87}\n",
      "Client 23 label distribution: {2: 86, 3: 90}\n",
      "Client 24 label distribution: {7: 82, 0: 89}\n",
      "Client 25 label distribution: {5: 79, 0: 87}\n",
      "Client 26 label distribution: {2: 84, 5: 78}\n",
      "Client 27 label distribution: {9: 92, 0: 85}\n",
      "Client 28 label distribution: {8: 80, 1: 107}\n",
      "Client 29 label distribution: {1: 105, 4: 82}\n",
      "Client 30 label distribution: {2: 82, 8: 79}\n",
      "Client 31 label distribution: {1: 102, 7: 81}\n",
      "Client 32 label distribution: {6: 85, 2: 81}\n",
      "Client 33 label distribution: {1: 100, 7: 79}\n",
      "Client 34 label distribution: {7: 78, 4: 80}\n",
      "Client 35 label distribution: {9: 90, 6: 84}\n",
      "Client 36 label distribution: {0: 83, 9: 88}\n",
      "Client 37 label distribution: {2: 79, 1: 98}\n",
      "Client 38 label distribution: {0: 82, 4: 79}\n",
      "Client 39 label distribution: {3: 88, 0: 80}\n",
      "Client 40 label distribution: {3: 86, 0: 78}\n",
      "Client 41 label distribution: {7: 76, 8: 77}\n",
      "Client 42 label distribution: {7: 75, 8: 76}\n",
      "Client 43 label distribution: {1: 96, 3: 84}\n",
      "Client 44 label distribution: {8: 74, 1: 95}\n",
      "Client 45 label distribution: {7: 73, 4: 77}\n",
      "Client 46 label distribution: {5: 76, 7: 72}\n",
      "Client 47 label distribution: {1: 93, 4: 76}\n",
      "Client 48 label distribution: {9: 86, 6: 82}\n",
      "Client 49 label distribution: {1: 91, 3: 83}\n",
      "Client 50 label distribution: {7: 70, 4: 74}\n",
      "Client 51 label distribution: {5: 75, 2: 77}\n",
      "Client 52 label distribution: {8: 73, 0: 77}\n",
      "Client 53 label distribution: {1: 89, 8: 71}\n",
      "Client 54 label distribution: {2: 76, 8: 70}\n",
      "Client 55 label distribution: {3: 81, 1: 87}\n",
      "Client 56 label distribution: {6: 80, 1: 85}\n",
      "Client 57 label distribution: {2: 74, 1: 84}\n",
      "Client 58 label distribution: {3: 80, 4: 73}\n",
      "Client 59 label distribution: {1: 82, 0: 75}\n",
      "Client 60 label distribution: {9: 85, 2: 73}\n",
      "Client 61 label distribution: {7: 69, 4: 71}\n",
      "Client 62 label distribution: {4: 70, 2: 71}\n",
      "Client 63 label distribution: {4: 68, 0: 74}\n",
      "Client 64 label distribution: {6: 79, 8: 68}\n",
      "Client 65 label distribution: {8: 67, 5: 73}\n",
      "Client 66 label distribution: {0: 72, 4: 67}\n",
      "Client 67 label distribution: {7: 67, 9: 83}\n",
      "Client 68 label distribution: {9: 81, 6: 77}\n",
      "Client 69 label distribution: {9: 80, 5: 72}\n",
      "Client 70 label distribution: {5: 70, 0: 71}\n",
      "Client 71 label distribution: {9: 78, 0: 70}\n",
      "Client 72 label distribution: {6: 76, 2: 70}\n",
      "Client 73 label distribution: {3: 78, 5: 69}\n",
      "Client 74 label distribution: {2: 69, 4: 66}\n",
      "Client 75 label distribution: {4: 64, 1: 80}\n",
      "Client 76 label distribution: {4: 63, 5: 67}\n",
      "Client 77 label distribution: {2: 67, 3: 76}\n",
      "Client 78 label distribution: {4: 62, 1: 79}\n",
      "Client 79 label distribution: {7: 66, 0: 68}\n",
      "Client 80 label distribution: {5: 66, 3: 75}\n",
      "Client 81 label distribution: {9: 76, 7: 65}\n",
      "Client 82 label distribution: {1: 77, 3: 73}\n",
      "Client 83 label distribution: {9: 75, 8: 66}\n",
      "Client 84 label distribution: {2: 66, 9: 73}\n",
      "Client 85 label distribution: {0: 67, 4: 61}\n",
      "Client 86 label distribution: {1: 76, 9: 72}\n",
      "Client 87 label distribution: {0: 65, 9: 71}\n",
      "Client 88 label distribution: {9: 69, 7: 63}\n",
      "Client 89 label distribution: {0: 64, 2: 65}\n",
      "Client 90 label distribution: {9: 68, 8: 64}\n",
      "Client 91 label distribution: {9: 66, 3: 72}\n",
      "Client 92 label distribution: {2: 63, 9: 65}\n",
      "Client 93 label distribution: {7: 62, 9: 64}\n",
      "Client 94 label distribution: {8: 63, 7: 61}\n",
      "Client 95 label distribution: {7: 60, 5: 65}\n",
      "Client 96 label distribution: {4: 59, 5: 64}\n",
      "Client 97 label distribution: {2: 62, 5: 62}\n",
      "Client 98 label distribution: {2: 61, 4: 58}\n",
      "Client 99 label distribution: {3: 70, 8: 62}\n",
      "\n",
      "Validation Set Label Distribution:\n",
      "Client 0 label distribution: {9: 23, 0: 23}\n",
      "Client 1 label distribution: {5: 21, 3: 25}\n",
      "Client 2 label distribution: {1: 26, 8: 23}\n",
      "Client 3 label distribution: {3: 24, 8: 22}\n",
      "Client 4 label distribution: {7: 25, 0: 23}\n",
      "Client 5 label distribution: {2: 23, 8: 22}\n",
      "Client 6 label distribution: {3: 24, 5: 21}\n",
      "Client 7 label distribution: {9: 23, 5: 20}\n",
      "Client 8 label distribution: {8: 22, 9: 23}\n",
      "Client 9 label distribution: {0: 22, 8: 21}\n",
      "Client 10 label distribution: {3: 23, 1: 26}\n",
      "Client 11 label distribution: {8: 21, 3: 23}\n",
      "Client 12 label distribution: {0: 22, 5: 20}\n",
      "Client 13 label distribution: {2: 22, 1: 25}\n",
      "Client 14 label distribution: {0: 21, 9: 22}\n",
      "Client 15 label distribution: {1: 25, 9: 22}\n",
      "Client 16 label distribution: {5: 19, 1: 24}\n",
      "Client 17 label distribution: {0: 21, 3: 22}\n",
      "Client 18 label distribution: {7: 25, 8: 20}\n",
      "Client 19 label distribution: {7: 24, 6: 23}\n",
      "Client 20 label distribution: {1: 24, 0: 21}\n",
      "Client 21 label distribution: {3: 22, 7: 24}\n",
      "Client 22 label distribution: {7: 24, 8: 20}\n",
      "Client 23 label distribution: {6: 22, 2: 22}\n",
      "Client 24 label distribution: {0: 20, 2: 21}\n",
      "Client 25 label distribution: {7: 23, 9: 21}\n",
      "Client 26 label distribution: {0: 20, 6: 22}\n",
      "Client 27 label distribution: {3: 21, 0: 19}\n",
      "Client 28 label distribution: {7: 23, 1: 23}\n",
      "Client 29 label distribution: {2: 21, 9: 21}\n",
      "Client 30 label distribution: {4: 23, 9: 20}\n",
      "Client 31 label distribution: {5: 19, 2: 21}\n",
      "Client 32 label distribution: {5: 19, 8: 20}\n",
      "Client 33 label distribution: {6: 21, 1: 23}\n",
      "Client 34 label distribution: {9: 20, 6: 21}\n",
      "Client 35 label distribution: {4: 23, 1: 22}\n",
      "Client 36 label distribution: {5: 18, 3: 21}\n",
      "Client 37 label distribution: {9: 20, 8: 19}\n",
      "Client 38 label distribution: {2: 20, 4: 22}\n",
      "Client 39 label distribution: {4: 22, 3: 21}\n",
      "Client 40 label distribution: {3: 20, 7: 22}\n",
      "Client 41 label distribution: {6: 20, 1: 22}\n",
      "Client 42 label distribution: {9: 19, 7: 22}\n",
      "Client 43 label distribution: {0: 19, 5: 18}\n",
      "Client 44 label distribution: {6: 20, 4: 21}\n",
      "Client 45 label distribution: {0: 19, 4: 21}\n",
      "Client 46 label distribution: {8: 19, 2: 20}\n",
      "Client 47 label distribution: {2: 19, 3: 20}\n",
      "Client 48 label distribution: {1: 21, 9: 19}\n",
      "Client 49 label distribution: {6: 20, 7: 21}\n",
      "Client 50 label distribution: {1: 21, 2: 19}\n",
      "Client 51 label distribution: {0: 18, 5: 17}\n",
      "Client 52 label distribution: {8: 18, 4: 20}\n",
      "Client 53 label distribution: {1: 20, 3: 19}\n",
      "Client 54 label distribution: {1: 20, 7: 21}\n",
      "Client 55 label distribution: {3: 19, 7: 20}\n",
      "Client 56 label distribution: {6: 19, 7: 20}\n",
      "Client 57 label distribution: {6: 19, 2: 19}\n",
      "Client 58 label distribution: {1: 20, 4: 20}\n",
      "Client 59 label distribution: {7: 20, 1: 19}\n",
      "Client 60 label distribution: {5: 17, 9: 18}\n",
      "Client 61 label distribution: {8: 18, 4: 20}\n",
      "Client 62 label distribution: {4: 19, 7: 19}\n",
      "Client 63 label distribution: {3: 19, 9: 18}\n",
      "Client 64 label distribution: {1: 19, 6: 18}\n",
      "Client 65 label distribution: {9: 18, 2: 18}\n",
      "Client 66 label distribution: {7: 19, 6: 18}\n",
      "Client 67 label distribution: {4: 19, 8: 18}\n",
      "Client 68 label distribution: {9: 17, 3: 18}\n",
      "Client 69 label distribution: {9: 17, 0: 18}\n",
      "Client 70 label distribution: {4: 18, 0: 17}\n",
      "Client 71 label distribution: {8: 17, 1: 18}\n",
      "Client 72 label distribution: {3: 18, 2: 18}\n",
      "Client 73 label distribution: {5: 17, 4: 18}\n",
      "Client 74 label distribution: {4: 18, 5: 16}\n",
      "Client 75 label distribution: {9: 17, 1: 18}\n",
      "Client 76 label distribution: {7: 18, 8: 17}\n",
      "Client 77 label distribution: {5: 16, 7: 18}\n",
      "Client 78 label distribution: {6: 18, 8: 17}\n",
      "Client 79 label distribution: {1: 18, 8: 16}\n",
      "Client 80 label distribution: {7: 18, 5: 16}\n",
      "Client 81 label distribution: {9: 16, 3: 17}\n",
      "Client 82 label distribution: {2: 18, 5: 15}\n",
      "Client 83 label distribution: {8: 16, 2: 17}\n",
      "Client 84 label distribution: {5: 15, 6: 17}\n",
      "Client 85 label distribution: {8: 16, 4: 17}\n",
      "Client 86 label distribution: {0: 17, 7: 17}\n",
      "Client 87 label distribution: {3: 17, 7: 17}\n",
      "Client 88 label distribution: {4: 17, 0: 17}\n",
      "Client 89 label distribution: {7: 17, 9: 16}\n",
      "Client 90 label distribution: {7: 16, 4: 17}\n",
      "Client 91 label distribution: {9: 16, 7: 16}\n",
      "Client 92 label distribution: {5: 15, 2: 17}\n",
      "Client 93 label distribution: {8: 15, 4: 16}\n",
      "Client 94 label distribution: {2: 17, 7: 16}\n",
      "Client 95 label distribution: {3: 17, 1: 17}\n",
      "Client 96 label distribution: {4: 16, 0: 16}\n",
      "Client 97 label distribution: {8: 15, 5: 15}\n",
      "Client 98 label distribution: {7: 15, 6: 17}\n",
      "Client 99 label distribution: {1: 17, 5: 14}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Number of clients and non-IID split\n",
    "train_data_size = len(mnist_train) // num_clients\n",
    "val_data_size = len(mnist_val) // num_clients\n",
    "\n",
    "if split == \"NONIID\":\n",
    "    \n",
    "    # Create indices for each class\n",
    "    train_class_indices = {i: np.where(np.array(mnist_train.targets) == i)[0] for i in range(num_classes)}\n",
    "    val_class_indices = {i: np.where(np.array(mnist_val.targets) == i)[0] for i in range(num_classes)}\n",
    "\n",
    "    train_indices = []  # Initialize training indices\n",
    "    val_indices = []    # Initialize validation indices\n",
    "\n",
    "    # Randomize the order of classes for validation\n",
    "    shuffled_classes = np.random.permutation(num_classes)\n",
    "\n",
    "    for client_id in range(num_clients):\n",
    "        # Choose random classes for training\n",
    "        chosen_train_classes = np.random.choice(num_classes, classes_per_client, replace=False)\n",
    "        train_client_idx = []\n",
    "\n",
    "        # Assign validation classes independently\n",
    "        chosen_val_classes = np.random.choice(shuffled_classes, classes_per_client, replace=False)\n",
    "        val_client_idx = []\n",
    "\n",
    "        for cls in chosen_train_classes:\n",
    "            train_cls_size = len(train_class_indices[cls]) // (num_clients // classes_per_client)\n",
    "            train_cls_idx = np.random.choice(train_class_indices[cls], train_cls_size, replace=False)\n",
    "            train_client_idx.extend(train_cls_idx)\n",
    "            train_class_indices[cls] = np.setdiff1d(train_class_indices[cls], train_cls_idx)  # Avoid duplication\n",
    "\n",
    "        for cls in chosen_val_classes:\n",
    "            val_cls_size = len(val_class_indices[cls]) // (num_clients // classes_per_client)\n",
    "            val_cls_idx = np.random.choice(val_class_indices[cls], val_cls_size, replace=False)\n",
    "            val_client_idx.extend(val_cls_idx)\n",
    "            val_class_indices[cls] = np.setdiff1d(val_class_indices[cls], val_cls_idx)  # Avoid duplication\n",
    "\n",
    "        train_indices.append(train_client_idx)\n",
    "        val_indices.append(val_client_idx)\n",
    "\n",
    "    # Create datasets and DataLoaders for each client\n",
    "    train_datasets = [Subset(mnist_train, indices) for indices in train_indices]\n",
    "    train_loaders = [DataLoader(ds, batch_size=batch_size, shuffle=True) for ds in train_datasets]\n",
    "\n",
    "    val_datasets = [Subset(mnist_val, indices) for indices in val_indices]\n",
    "    val_loaders = [DataLoader(ds, batch_size=batch_size, shuffle=True) for ds in val_datasets]\n",
    "\n",
    "else:\n",
    "    \n",
    "    # Split the training data into smaller datasets for each client\n",
    "    train_datasets = random_split(mnist_train, [train_data_size] * num_clients)\n",
    "    train_loaders = [DataLoader(ds, batch_size=batch_size, shuffle=True) for ds in train_datasets]\n",
    "    val_datasets = random_split(mnist_train, [train_data_size] * num_clients)\n",
    "    val_loaders = [DataLoader(ds, batch_size=batch_size, shuffle=True) for ds in train_datasets]\n",
    "\n",
    "# val_loaders = DataLoader(mnist_val, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "print(f\"Simulated {num_clients} clients, each with {train_data_size} training samples, and {len(mnist_val)} validation samples\")\n",
    "# Debugging: Output distribution of classes for all clients\n",
    "print(\"Training Set Label Distribution:\")\n",
    "for i, client_dataset in enumerate(train_datasets):\n",
    "    client_loader = torch.utils.data.DataLoader(client_dataset, batch_size=len(client_dataset))\n",
    "    client_samples, client_labels = next(iter(client_loader))\n",
    "    label_counts = Counter(client_labels.tolist())\n",
    "    print(f\"Client {i} label distribution: {dict(label_counts)}\")\n",
    "\n",
    "print(\"\\nValidation Set Label Distribution:\")\n",
    "for i, client_dataset in enumerate(val_datasets):\n",
    "    client_loader = torch.utils.data.DataLoader(client_dataset, batch_size=len(client_dataset))\n",
    "    client_samples, client_labels = next(iter(client_loader))\n",
    "    label_counts = Counter(client_labels.tolist())\n",
    "    print(f\"Client {i} label distribution: {dict(label_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optionally distribute the shared data among clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shared_fraction > 0.0:\n",
    "    alpha = 0.05    # Each client gets partition of the shared data\n",
    "\n",
    "    shared_loader = torch.utils.data.DataLoader(mnist_train_shared, batch_size=len(mnist_train_shared))\n",
    "    shared_samples, shared_labels = next(iter(shared_loader))\n",
    "    num_shared_samples = int(alpha * len(shared_samples))\n",
    "\n",
    "    merged_train_datasets = []\n",
    "    for client_dataset in train_datasets:\n",
    "        client_loader = torch.utils.data.DataLoader(client_dataset, batch_size=len(client_dataset))\n",
    "        client_samples, client_labels = next(iter(client_loader))\n",
    "        \n",
    "        # Combine shared and local data\n",
    "        combined_samples = torch.cat([client_samples, shared_samples[:num_shared_samples]])\n",
    "        combined_labels = torch.cat([client_labels, shared_labels[:num_shared_samples]])\n",
    "        merged_train_dataset = torch.utils.data.TensorDataset(combined_samples, combined_labels)\n",
    "        merged_train_datasets.append(merged_train_dataset)\n",
    "\n",
    "    train_loaders = [DataLoader(ds, batch_size=batch_size, shuffle=True) for ds in merged_train_datasets]\n",
    "\n",
    "    # Display the label distribution for each client\n",
    "    for i, client_dataset in enumerate(merged_train_datasets):\n",
    "        client_loader = torch.utils.data.DataLoader(client_dataset, batch_size=len(client_dataset))\n",
    "        client_samples, client_labels = next(iter(client_loader))\n",
    "        label_counts = Counter(client_labels.tolist())\n",
    "        print(f\"Client {i} label distribution: {dict(label_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up and initialize the Global Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initialization: Instantiate the global model (server)\n",
    "global_model = QuantStubModel(q=quantize)\n",
    "if(quantize):\n",
    "    global_model.qconfig = torch.quantization.get_default_qat_qconfig(\"fbgemm\")\n",
    "    torch.quantization.prepare_qat(global_model, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clients\n",
    "\n",
    "### Client Creation\n",
    "We create clients with various resources, in which we take into account, speed, availability, battery level, bandwidth, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "for i in range(num_clients):\n",
    "    mock_resources = ClientResources.generate_random((len(train_datasets[i]), len(train_datasets[i])))\n",
    "    new_client = Client(id=i, resources=mock_resources, dataset=train_datasets[i], dataloader=train_loaders[i], val_loader=val_loaders[i])\n",
    "    clients.append(new_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_selection_with_constraints(clients, use_deadline: bool, cutoff: float):\n",
    "    \"\"\"\n",
    "    Select clients based on their resources and constraints\n",
    "    \n",
    "    Args:\n",
    "    - clients: list of Client objects\n",
    "    - use_deadline: whether to use a deadline for client selection\n",
    "    - cutoff: deadline for client selection if using deadline, otherwise fraction of clients to select\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate update times for all clients\n",
    "    client_times = [\n",
    "        (client, client.resources.dataset_size / client.resources.speed_factor)  # (Client object, update_time)\n",
    "        for client in clients\n",
    "    ]\n",
    "    \n",
    "    # Sort clients by their update time\n",
    "    client_times.sort(key=lambda x: x[1])\n",
    "    selected_clients = []\n",
    "    #total_time = 0\n",
    "\n",
    "    #print(deadline)\n",
    "    # Select clients within the deadline\n",
    "    if use_deadline:\n",
    "        for client, update_time in client_times:\n",
    "            #print('ut:', update_time)\n",
    "            if update_time <= cutoff:\n",
    "                selected_clients.append(client)\n",
    "            else:\n",
    "                break  # Stop once adding a client exceeds the deadline\n",
    "    else:\n",
    "        # Select clients based on cutoff fraction\n",
    "        selected_clients_with_times = client_times[:int(cutoff * len(client_times))]\n",
    "        selected_clients = [client for client, _ in selected_clients_with_times]\n",
    "\n",
    "    # TODO: fix client choice\n",
    "    if len(selected_clients) == 0:\n",
    "        selected_clients.append(clients[0])\n",
    "\n",
    "    return selected_clients\n",
    "\n",
    "def select_indices(n, k):\n",
    "    return random.sample(range(n), k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(global_model, val_loaders):\n",
    "\n",
    "    global_model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_loader in val_loaders:\n",
    "            client_loss = 0.0\n",
    "            client_correct = 0\n",
    "            client_samples = 0\n",
    "\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = global_model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                client_loss += loss.item() * len(labels)  # Accumulate loss weighted by batch size\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                client_correct += (preds == labels).sum().item()  # Count correct predictions\n",
    "                client_samples += len(labels)  # Track number of samples\n",
    "\n",
    "            # Accumulate client metrics into global metrics\n",
    "            total_loss += client_loss\n",
    "            total_correct += client_correct\n",
    "            total_samples += client_samples\n",
    "\n",
    "    # Compute global averages\n",
    "    avg_loss = total_loss / total_samples if total_samples > 0 else 0.0\n",
    "    avg_accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "    return avg_loss, avg_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Federated Learning Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function for client training\n",
    "def train_client_parallel(client, global_model, epochs=1, lr=0.001, quantize=False, lambda_kure=0.0, delta=0.0, setup='standard',bit_widths=[32]):\n",
    "    #print(f\"Training client {client.id} with resources {client.resources}\")\n",
    "    return client.id, client.train(global_model, epochs, lr, quantize, lambda_kure, delta, setup, bit_widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: False\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Generate a unique log directory based on the current time\n",
    "run_number = hp[\"run_number\"] + datetime.now().strftime('-%m-%d-%H-%M')\n",
    "log_dir = f\"./logs/{hp['run_id']}/run_{run_number}-{datetime.now().strftime('%m-%d-%H-%M')}\"\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "hyperparams_text = \"\\n\".join([f\"{key}: {value}\" for key, value in hp.items()])\n",
    "start_time = time.time()\n",
    "\n",
    "# Federated Learning with FedCS Client Selection\n",
    "num_rounds = hp[\"num_rounds\"]\n",
    "epochs = hp[\"epochs\"]\n",
    "round_deadline = hp[\"deadline\"]  # Example round deadline (in ARBITRARY time units)\n",
    "cutoff = hp[\"cutoff\"]  # Fraction of clients to select in each round\n",
    "print(\"GPU available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "-> Resource requested from 72 clients, 48 clients fulfilled the criteria\n",
      "Training loss after round 1: 0.6156712548936617\n",
      "Global model updated for round 1\n",
      "Validation Loss: 1.6071, Validation Accuracy: 48.45%\n",
      "Round 2\n",
      "-> Resource requested from 97 clients, 64 clients fulfilled the criteria\n",
      "Training loss after round 2: 0.5942946216557177\n",
      "Global model updated for round 2\n",
      "Validation Loss: 1.4968, Validation Accuracy: 58.42%\n",
      "Round 3\n",
      "-> Resource requested from 56 clients, 37 clients fulfilled the criteria\n",
      "Training loss after round 3: 0.5757545152351863\n",
      "Global model updated for round 3\n",
      "Validation Loss: 1.4744, Validation Accuracy: 51.01%\n",
      "Round 4\n",
      "-> Resource requested from 6 clients, 4 clients fulfilled the criteria\n",
      "Training loss after round 4: 0.4614967534318567\n",
      "Global model updated for round 4\n",
      "Validation Loss: 2.1775, Validation Accuracy: 27.33%\n",
      "Round 5\n",
      "-> Resource requested from 19 clients, 12 clients fulfilled the criteria\n",
      "Training loss after round 5: 0.7399271483636566\n",
      "Global model updated for round 5\n",
      "Validation Loss: 1.6756, Validation Accuracy: 35.03%\n",
      "\n",
      "Elapsed time: 30.47 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Conduct federated learning rounds\n",
    "for round_num in range(num_rounds):\n",
    "    print(f\"Round {round_num + 1}\")\n",
    "    \n",
    "    # 2. Resource Request\n",
    "    k = random.randint(1, num_clients)\n",
    "    resource_requested_clients = random.sample(range(num_clients), k)\n",
    "    requested_clients = [clients[i] for i in resource_requested_clients]\n",
    "    \n",
    "    # 3. Client Selection: Collect client updates\n",
    "    if use_client_selection:\n",
    "        selected_train_clients = client_selection_with_constraints(requested_clients, use_deadline=False, cutoff=cutoff)\n",
    "    else:\n",
    "        selected_train_clients = requested_clients\n",
    "    print(f\"-> Resource requested from {len(resource_requested_clients)} clients, {len(selected_train_clients)} clients fulfilled the criteria\")\n",
    "\n",
    "    client_states = []\n",
    "    total_loss = 0\n",
    "    num_batches = len(selected_train_clients)\n",
    "    # Parallelize client training\n",
    "    with ThreadPoolExecutor(max_workers=len(selected_train_clients)) as executor:\n",
    "        futures = {\n",
    "            executor.submit(\n",
    "                train_client_parallel, \n",
    "                client, \n",
    "                global_model, \n",
    "                epochs=1,\n",
    "                lr=lr,\n",
    "                quantize=quantize,\n",
    "                lambda_kure=lambda_kure,\n",
    "                delta=delta,\n",
    "                setup=setup,\n",
    "                bit_widths=bit_widths\n",
    "                ): client\n",
    "            for client in selected_train_clients\n",
    "        }\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            client_id, (client_state, client_loss) = future.result()\n",
    "            # print(f\"Client {client_id} completed training.\")\n",
    "            client_states.append(client_state)\n",
    "            total_loss += client_loss\n",
    "\n",
    "    # Compute average training loss\n",
    "    avg_round_training_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "    writer.add_scalar(\"Metrics/Training loss\", avg_round_training_loss, round_num + 1)\n",
    "    print(f\"Training loss after round {round_num + 1}: {avg_round_training_loss}\")\n",
    "\n",
    "    # 6. Aggregation: Aggregate updates using Federated Averaging\n",
    "    new_global_state = fl.federated_averaging(global_model, client_states)  \n",
    "    global_model.load_state_dict(new_global_state)\n",
    "    print(f\"Global model updated for round {round_num + 1}\")\n",
    "\n",
    "    # 7. Evaluate on Validation Set\n",
    "    val_loaders = [client.val_loader for client in clients]  # Get all validation loaders\n",
    "    val_loss, val_accuracy = validate_model(global_model, val_loaders)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2%}\")\n",
    "    \n",
    "    # Optional: Log metrics for visualization\n",
    "    writer.add_scalar(\"Metrics/Validation Loss\", val_loss, round_num + 1)\n",
    "    writer.add_scalar(\"Metrics/Validation Accuracy\", val_accuracy, round_num + 1)\n",
    "\n",
    "if quantize:\n",
    "    torch.quantization.convert(global_model, inplace=True)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global model accuracy: 41.07%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_accuracy = correct / total\n",
    "    print(f\"Global model accuracy: {test_accuracy:.2%}\")\n",
    "    return test_accuracy\n",
    "    \n",
    "# Evaluate the model on the test dataset\n",
    "test_accuracy = evaluate_model(global_model, test_loader)\n",
    "\n",
    "# End TensorBoard writer\n",
    "final_metrics = {}\n",
    "hp_cleaned = {k: v for k, v in hp.items() if isinstance(v, (int, float, str, bool, torch.Tensor))}\n",
    "writer.add_hparams(hp_cleaned, final_metrics)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global model saved at ./saved_models/global_model_results_noniid2_standard_noshared-12-16-12-45.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the final model\n",
    "model_save_path = f\"./saved_models/global_model_{hp['run_id']}_{run_number}.pth\"\n",
    "torch.save(global_model.state_dict(), model_save_path)\n",
    "print(f\"Global model saved at {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

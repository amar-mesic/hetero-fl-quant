{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we develop heterogeneity in the clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from itertools import groupby\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the src directory\n",
    "src_path = os.path.abspath('../src')\n",
    "# Add src_path to sys.path\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    \n",
    "import fl\n",
    "from client import Client, ClientResources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 60000, Test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# download dataset and preprocess/transform\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define transformations for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to range [-1, 1]\n",
    "])\n",
    "\n",
    "# Download and load MNIST dataset\n",
    "mnist_train = datasets.MNIST(root=\"../data\", train=True, transform=transform, download=True)\n",
    "mnist_test = datasets.MNIST(root=\"../data\", train=False, transform=transform, download=True)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Train dataset size: {len(mnist_train)}, Test dataset size: {len(mnist_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated 5 clients, each with 12000 training samples.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Define the number of clients and split sizes\n",
    "num_clients = 5\n",
    "client_data_size = len(mnist_train) // num_clients\n",
    "\n",
    "# Split the training data into smaller datasets for each client\n",
    "client_datasets = random_split(mnist_train, [client_data_size] * num_clients)\n",
    "\n",
    "# Create DataLoaders for each client\n",
    "client_loaders = [DataLoader(ds, batch_size=32, shuffle=True) for ds in client_datasets]\n",
    "\n",
    "# Test DataLoader for evaluation\n",
    "test_loader = DataLoader(mnist_test, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Simulated {num_clients} clients, each with {client_data_size} training samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dummy Clients with different computational speeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up and initialize the Global Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiate the global model (server)\n",
    "model = fl.create_model()\n",
    "global_model = model\n",
    "print(global_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create client instances\n",
    "num_clients = 5\n",
    "client_speeds = [1.0, 1.5, 2, 1.5, 1.75]  # Simulated speed factors\n",
    "client_datasets = random_split(mnist_train, [len(mnist_train) // num_clients] * num_clients)\n",
    "\n",
    "resources = ClientResources(\n",
    "    speed_factor=1.5,\n",
    "    battery_level=80,\n",
    "    bandwidth=10.0,\n",
    "    dataset_size=1000,\n",
    "    CPU_available=True,\n",
    "    CPU_memory_availability=64.0,\n",
    "    GPU_available=True,\n",
    "    GPU_memory_availability=16.0,\n",
    ")\n",
    "\n",
    "clients = []\n",
    "for i in range(num_clients):\n",
    "    mock_resources = ClientResources.generate_random((len(client_datasets[i]), len(client_datasets[i])))\n",
    "\n",
    "    new_client = Client(id=i, resources=mock_resources, dataset=client_datasets[i])\n",
    "    clients.append(new_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from multiprocessing import Pool\n",
    "\n",
    "# def parallel_train(client):\n",
    "#     speed, client_loader = client\n",
    "#     return train_client(global_model, client_loader, speed_factor=speed)\n",
    "\n",
    "# with Pool(processes=len(client_loaders)) as pool:\n",
    "#     client_states = pool.map(parallel_train, zip(client_speeds, client_loaders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Federated Learning Round 1 ===\n",
      "\n",
      "Training client 0 with resources ClientResources(speed_factor=1.7160021044797742, battery_level=50.704235090809576, bandwidth=51.33546357231246, dataset_size=12000, CPU_available=True, CPU_memory_availability=119.05571570773346, GPU_available=True, GPU_memory_availability=31.669893043095335)\n",
      "\n",
      "Training client 1 with resources ClientResources(speed_factor=1.6969267879880643, battery_level=94.14238177520939, bandwidth=39.927809165515164, dataset_size=12000, CPU_available=True, CPU_memory_availability=58.40438549768966, GPU_available=False, GPU_memory_availability=0)\n",
      "\n",
      "Training client 2 with resources ClientResources(speed_factor=1.9723324402252151, battery_level=21.132345241248185, bandwidth=85.70204887906986, dataset_size=12000, CPU_available=False, CPU_memory_availability=53.7062699297276, GPU_available=False, GPU_memory_availability=0)\n",
      "\n",
      "Training client 3 with resources ClientResources(speed_factor=1.6215943869529335, battery_level=78.85237043272897, bandwidth=20.768823997689175, dataset_size=12000, CPU_available=False, CPU_memory_availability=19.806302791677254, GPU_available=True, GPU_memory_availability=21.990779344973717)\n",
      "\n",
      "Training client 4 with resources ClientResources(speed_factor=1.2510099579345724, battery_level=21.40153407208311, bandwidth=26.221301201624456, dataset_size=12000, CPU_available=True, CPU_memory_availability=127.14758253728934, GPU_available=False, GPU_memory_availability=0)\n",
      "Training round complete in 38.54: seconds\n",
      "Training round complete in 38.56: seconds\n",
      "Training round complete in 38.60: seconds\n",
      "Training round complete in 38.62: seconds\n",
      "Training round complete in 38.62: seconds\n",
      "Client simulated to take 48.21 seconds for training\n",
      "Client 4 completed training.\n",
      "Client simulated to take 62.53 seconds for training\n",
      "Client 3 completed training.\n",
      "Client simulated to take 65.54 seconds for training\n",
      "Client 1 completed training.\n",
      "Client simulated to take 66.28 seconds for training\n",
      "Client 0 completed training.\n",
      "Client simulated to take 76.14 seconds for training\n",
      "Client 2 completed training.\n",
      "Global model updated after round 1\n",
      "\n",
      "=== Federated Learning Round 2 ===\n",
      "\n",
      "Training client 0 with resources ClientResources(speed_factor=1.7160021044797742, battery_level=50.704235090809576, bandwidth=51.33546357231246, dataset_size=12000, CPU_available=True, CPU_memory_availability=119.05571570773346, GPU_available=True, GPU_memory_availability=31.669893043095335)\n",
      "\n",
      "Training client 1 with resources ClientResources(speed_factor=1.6969267879880643, battery_level=94.14238177520939, bandwidth=39.927809165515164, dataset_size=12000, CPU_available=True, CPU_memory_availability=58.40438549768966, GPU_available=False, GPU_memory_availability=0)\n",
      "\n",
      "Training client 2 with resources ClientResources(speed_factor=1.9723324402252151, battery_level=21.132345241248185, bandwidth=85.70204887906986, dataset_size=12000, CPU_available=False, CPU_memory_availability=53.7062699297276, GPU_available=False, GPU_memory_availability=0)\n",
      "\n",
      "Training client 3 with resources ClientResources(speed_factor=1.6215943869529335, battery_level=78.85237043272897, bandwidth=20.768823997689175, dataset_size=12000, CPU_available=False, CPU_memory_availability=19.806302791677254, GPU_available=True, GPU_memory_availability=21.990779344973717)\n",
      "\n",
      "Training client 4 with resources ClientResources(speed_factor=1.2510099579345724, battery_level=21.40153407208311, bandwidth=26.221301201624456, dataset_size=12000, CPU_available=True, CPU_memory_availability=127.14758253728934, GPU_available=False, GPU_memory_availability=0)\n",
      "Training round complete in 38.93: seconds\n",
      "Training round complete in 38.94: seconds\n",
      "Training round complete in 38.98: seconds\n",
      "Training round complete in 38.99: seconds\n",
      "Training round complete in 39.00: seconds\n",
      "Client simulated to take 48.71 seconds for training\n",
      "Client 4 completed training.\n",
      "Client simulated to take 63.15 seconds for training\n",
      "Client 3 completed training.\n",
      "Client simulated to take 66.17 seconds for training\n",
      "Client 1 completed training.\n",
      "Client simulated to take 66.89 seconds for training\n",
      "Client 0 completed training.\n",
      "Client simulated to take 76.93 seconds for training\n",
      "Client 2 completed training.\n",
      "Global model updated after round 2\n",
      "\n",
      "=== Federated Learning Round 3 ===\n",
      "\n",
      "Training client 0 with resources ClientResources(speed_factor=1.7160021044797742, battery_level=50.704235090809576, bandwidth=51.33546357231246, dataset_size=12000, CPU_available=True, CPU_memory_availability=119.05571570773346, GPU_available=True, GPU_memory_availability=31.669893043095335)\n",
      "\n",
      "Training client 1 with resources ClientResources(speed_factor=1.6969267879880643, battery_level=94.14238177520939, bandwidth=39.927809165515164, dataset_size=12000, CPU_available=True, CPU_memory_availability=58.40438549768966, GPU_available=False, GPU_memory_availability=0)\n",
      "\n",
      "Training client 2 with resources ClientResources(speed_factor=1.9723324402252151, battery_level=21.132345241248185, bandwidth=85.70204887906986, dataset_size=12000, CPU_available=False, CPU_memory_availability=53.7062699297276, GPU_available=False, GPU_memory_availability=0)\n",
      "\n",
      "Training client 3 with resources ClientResources(speed_factor=1.6215943869529335, battery_level=78.85237043272897, bandwidth=20.768823997689175, dataset_size=12000, CPU_available=False, CPU_memory_availability=19.806302791677254, GPU_available=True, GPU_memory_availability=21.990779344973717)\n",
      "\n",
      "Training client 4 with resources ClientResources(speed_factor=1.2510099579345724, battery_level=21.40153407208311, bandwidth=26.221301201624456, dataset_size=12000, CPU_available=True, CPU_memory_availability=127.14758253728934, GPU_available=False, GPU_memory_availability=0)\n",
      "Training round complete in 38.28: seconds\n",
      "Training round complete in 38.32: seconds\n",
      "Training round complete in 38.37: seconds\n",
      "Training round complete in 38.37: seconds\n",
      "Training round complete in 38.38: seconds\n",
      "Client simulated to take 47.89 seconds for training\n",
      "Client 4 completed training.\n",
      "Client simulated to take 62.22 seconds for training\n",
      "Client 3 completed training.\n",
      "Client simulated to take 65.11 seconds for training\n",
      "Client 1 completed training.\n",
      "Client simulated to take 65.85 seconds for training\n",
      "Client 0 completed training.\n",
      "Client simulated to take 75.58 seconds for training\n",
      "Client 2 completed training.\n",
      "Global model updated after round 3\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Wrapper function for client training\n",
    "def train_client_parallel(client, global_model, epochs=1):\n",
    "    print(f\"\\nTraining client {client.id} with resources {client.resources}\")\n",
    "    return client.id, client.train(global_model, epochs)\n",
    "\n",
    "# Number of rounds to simulate\n",
    "num_rounds = 3\n",
    "\n",
    "# List to store global model states over rounds (optional)\n",
    "global_model_states = []\n",
    "\n",
    "for round_num in range(num_rounds):\n",
    "    print(f\"\\n=== Federated Learning Round {round_num + 1} ===\")\n",
    "\n",
    "    # Parallelize client training\n",
    "    client_states = []\n",
    "    with ThreadPoolExecutor(max_workers=len(clients)) as executor:\n",
    "        futures = {executor.submit(train_client_parallel, client, global_model, 1): client for client in clients}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            client_id, client_state = future.result()\n",
    "            print(f\"Client {client_id} completed training.\")\n",
    "            client_states.append(client_state)\n",
    "    \n",
    "    # Aggregate client updates using Federated Averaging\n",
    "    new_global_state = fl.federated_averaging(global_model, client_states)\n",
    "    global_model.load_state_dict(new_global_state)\n",
    "\n",
    "    # Optionally save global model state for each round\n",
    "    # global_model_states.append(copy.deepcopy(global_model.state_dict()))\n",
    "\n",
    "    # Evaluate global model (optional)\n",
    "    print(f\"Global model updated after round {round_num + 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training client 0 with resources ClientResources(speed_factor=1.970175601083471, battery_level=44.412161174949844, bandwidth=42.17689437834442, dataset_size=30000, CPU_available=False, CPU_memory_availability=9.070395434254579, GPU_available=False, GPU_memory_availability=0)\n",
      "Training round complete in 5.67: seconds\n",
      "Client simulated to take 11.18 seconds for training\n",
      "\n",
      "Training client 1 with resources ClientResources(speed_factor=1.689800106109189, battery_level=37.42924574833511, bandwidth=56.57171983565547, dataset_size=30000, CPU_available=True, CPU_memory_availability=103.28883643824332, GPU_available=True, GPU_memory_availability=4.624544318161185)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m client \u001b[38;5;129;01min\u001b[39;00m clients:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining client \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with resources \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient\u001b[38;5;241m.\u001b[39mresources\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     client_state \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglobal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     client_states\u001b[38;5;241m.\u001b[39mappend(client_state)\n",
      "File \u001b[0;32m~/Documents/JI Courses/DML/hetero-fl-quant/src/client.py:121\u001b[0m, in \u001b[0;36mClient.train\u001b[0;34m(self, global_model, epochs)\u001b[0m\n\u001b[1;32m    119\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m local_model(inputs)\n\u001b[1;32m    120\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m--> 121\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    125\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/miniconda3/envs/dml/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dml/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train clients and collect their updates\n",
    "client_states = []\n",
    "for client in clients:\n",
    "    print(f\"\\nTraining client {client.id} with resources {client.resources}\")\n",
    "    client_state = client.train(global_model, epochs=1)\n",
    "    client_states.append(client_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1.0, <torch.utils.data.dataloader.DataLoader at 0x7fc7c599b0a0>)],\n",
       " [(1.5, <torch.utils.data.dataloader.DataLoader at 0x7fc7c599b0d0>),\n",
       "  (1.5, <torch.utils.data.dataloader.DataLoader at 0x7fc7a8bb1210>),\n",
       "  (1.75, <torch.utils.data.dataloader.DataLoader at 0x7fc7a8bb0f70>)],\n",
       " [(2, <torch.utils.data.dataloader.DataLoader at 0x7fc7c59988b0>)]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort clients into batches\n",
    "\n",
    "batches = []\n",
    "\n",
    "# sort the clients by speed\n",
    "sorted_clients = sorted(zip(client_speeds, client_loaders), key=lambda x: x[0])\n",
    "\n",
    "# Group clients in windows of 0.5 speed factor\n",
    "for speed, group in groupby(sorted_clients, key=lambda x: x[0] // 0.5):  # Group by speed range\n",
    "    batches.append(list(group))\n",
    "\n",
    "batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, <torch.utils.data.dataloader.DataLoader object at 0x7fc7c599b0a0>)]\n",
      "[(1.5, <torch.utils.data.dataloader.DataLoader object at 0x7fc7c599b0d0>), (1.5, <torch.utils.data.dataloader.DataLoader object at 0x7fc7a8bb1210>), (1.75, <torch.utils.data.dataloader.DataLoader object at 0x7fc7a8bb0f70>)]\n",
      "[(2, <torch.utils.data.dataloader.DataLoader object at 0x7fc7c59988b0>)]\n"
     ]
    }
   ],
   "source": [
    "for batch in batches:\n",
    "    print(batch)\n",
    "    # client_states = []\n",
    "    # for _, client_loader in batch:\n",
    "    #     client_state = train_client(global_model, client_loader, epochs=1)\n",
    "    #     client_states.append(client_state)\n",
    "    \n",
    "    # # Aggregate updates for the current batch\n",
    "    # new_global_state = federated_averaging(global_model, client_states)\n",
    "    # global_model.load_state_dict(new_global_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file is a WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from itertools import groupby\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the src directory\n",
    "src_path = os.path.abspath('../src')\n",
    "# Add src_path to sys.path\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    \n",
    "import fl\n",
    "from client import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 60000, Test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# download dataset and preprocess/transform\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define transformations for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to range [-1, 1]\n",
    "])\n",
    "\n",
    "# Download and load MNIST dataset\n",
    "mnist_train = datasets.MNIST(root=\"../data\", train=True, transform=transform, download=True)\n",
    "mnist_test = datasets.MNIST(root=\"../data\", train=False, transform=transform, download=True)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Train dataset size: {len(mnist_train)}, Test dataset size: {len(mnist_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated 5 clients, each with 12000 training samples.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Define the number of clients and split sizes\n",
    "num_clients = 5\n",
    "client_data_size = len(mnist_train) // num_clients\n",
    "\n",
    "# Split the training data into smaller datasets for each client\n",
    "client_datasets = random_split(mnist_train, [client_data_size] * num_clients)\n",
    "\n",
    "# Create DataLoaders for each client\n",
    "client_loaders = [DataLoader(ds, batch_size=32, shuffle=True) for ds in client_datasets]\n",
    "\n",
    "# Test DataLoader for evaluation\n",
    "test_loader = DataLoader(mnist_test, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Simulated {num_clients} clients, each with {client_data_size} training samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dummy Clients with different computational speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Client:\n",
    "#     def __init__(self, id, speed_factor, dataset, batch_size=32):\n",
    "#         \"\"\"\n",
    "#         Initialize a Client object.\n",
    "\n",
    "#         Parameters:\n",
    "#         - id (int): The ID of the client.\n",
    "#         - speed_factor (float): The speed factor of the client, which determines the training delay.\n",
    "#         - dataset (torch.utils.data.Dataset): The dataset used for training.\n",
    "#         - batch_size (int, optional): The batch size for the dataloader. Default is 32.\n",
    "#         \"\"\"\n",
    "#         self.id = id\n",
    "#         self.speed_factor = speed_factor\n",
    "#         self.dataset = dataset\n",
    "#         self.dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#     def train(self, global_model, epochs=1):\n",
    "#         \"\"\"\n",
    "#         Train the global model on the client's local dataset using Adam optimizer.\n",
    "\n",
    "#         Parameters:\n",
    "#         - global_model (torch.nn.Module): The global model to be trained.\n",
    "#         - epochs (int, optional): The number of training epochs. Default is 1.\n",
    "\n",
    "#         Returns:\n",
    "#         - state_dict (dict): The updated model parameters.\n",
    "#         \"\"\"\n",
    "#         # Directly copy the global model\n",
    "#         local_model = global_model\n",
    "#         local_model.load_state_dict(global_model.state_dict())\n",
    "        \n",
    "#         # Define the loss function and optimizer\n",
    "#         criterion = nn.CrossEntropyLoss()\n",
    "#         optimizer = optim.Adam(\n",
    "#             local_model.parameters(), \n",
    "#             lr=0.001, \n",
    "#             # learning hyperparameters can be set later\n",
    "#             # betas=(0.9, 0.99), \n",
    "#             # eps=1e-7, \n",
    "#             # weight_decay=1e-4\n",
    "#         )\n",
    "        \n",
    "#         # Simulate training delay based on speed_factor\n",
    "#         local_model.train()\n",
    "#         for epoch in range(int(epochs * self.speed_factor)):\n",
    "#             for inputs, labels in self.dataloader:\n",
    "#                 optimizer.zero_grad()\n",
    "#                 outputs = local_model(inputs)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "\n",
    "#         # Return updated model parameters\n",
    "#         return local_model.state_dict()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up and initialize the Global Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiate the global model (server)\n",
    "model = fl.create_model()\n",
    "global_model = model\n",
    "print(global_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create client instances\n",
    "num_clients = 5\n",
    "client_speeds = [1.0, 0.5, 0.25, 1.5, 0.75]  # Simulated speed factors\n",
    "client_datasets = random_split(mnist_train, [len(mnist_train) // num_clients] * num_clients)\n",
    "\n",
    "clients = []\n",
    "for i in range(num_clients):\n",
    "    new_client = Client(id=i, speed_factor=client_speeds[i], dataset=client_datasets[i])\n",
    "    clients.append(new_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training client 0 with speed 1.0\n",
      "Training client 1 with speed 0.5\n",
      "Training client 2 with speed 0.25\n",
      "Training client 3 with speed 1.5\n",
      "Training client 4 with speed 0.75\n"
     ]
    }
   ],
   "source": [
    "# Train clients and collect their updates\n",
    "client_states = []\n",
    "for client in clients:\n",
    "    print(f\"Training client {client.id} with speed {client.speed_factor}\")\n",
    "    client_state = client.train(global_model, epochs=1)\n",
    "    client_states.append(client_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function needs to be made functional\n",
    "\n",
    "def train_client(model, dataloader, speed_factor, epochs=1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Simulate slower/faster training based on speed_factor\n",
    "    for _ in range(int(epochs * speed_factor)):\n",
    "        pass  # Simulated work\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Client trained in {end_time - start_time:.2f} seconds\")\n",
    "    return model.state_dict()  # Return model state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0.25, <torch.utils.data.dataloader.DataLoader at 0x7fcd2c4c0400>)],\n",
       " [(0.5, <torch.utils.data.dataloader.DataLoader at 0x7fcd4299f970>),\n",
       "  (0.75, <torch.utils.data.dataloader.DataLoader at 0x7fcd25130430>)],\n",
       " [(1.0, <torch.utils.data.dataloader.DataLoader at 0x7fcd3d09a650>)],\n",
       " [(1.5, <torch.utils.data.dataloader.DataLoader at 0x7fcd25131b70>)]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort clients into batches\n",
    "\n",
    "batches = []\n",
    "\n",
    "# sort the clients by speed\n",
    "sorted_clients = sorted(zip(client_speeds, client_loaders), key=lambda x: x[0])\n",
    "\n",
    "# Group clients in windows of 0.5 speed factor\n",
    "for speed, group in groupby(sorted_clients, key=lambda x: x[0] // 0.5):  # Group by speed range\n",
    "    batches.append(list(group))\n",
    "\n",
    "batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.25, <torch.utils.data.dataloader.DataLoader object at 0x7fcd2c4c0400>)]\n",
      "[(0.5, <torch.utils.data.dataloader.DataLoader object at 0x7fcd4299f970>), (0.75, <torch.utils.data.dataloader.DataLoader object at 0x7fcd25130430>)]\n",
      "[(1.0, <torch.utils.data.dataloader.DataLoader object at 0x7fcd3d09a650>)]\n",
      "[(1.5, <torch.utils.data.dataloader.DataLoader object at 0x7fcd25131b70>)]\n"
     ]
    }
   ],
   "source": [
    "for batch in batches:\n",
    "    print(batch)\n",
    "    # client_states = []\n",
    "    # for _, client_loader in batch:\n",
    "    #     client_state = train_client(global_model, client_loader, epochs=1)\n",
    "    #     client_states.append(client_state)\n",
    "    \n",
    "    # # Aggregate updates for the current batch\n",
    "    # new_global_state = federated_averaging(global_model, client_states)\n",
    "    # global_model.load_state_dict(new_global_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

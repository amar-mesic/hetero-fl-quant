{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all needed packages\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the src directory\n",
    "src_path = os.path.abspath('../src')\n",
    "\n",
    "# Add src_path to sys.path\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    \n",
    "import fl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 60000, Test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# download dataset and preprocess/transform\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define transformations for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to range [-1, 1]\n",
    "])\n",
    "\n",
    "# Download and load MNIST dataset\n",
    "mnist_train = datasets.MNIST(root=\"../data\", train=True, transform=transform, download=True)\n",
    "mnist_test = datasets.MNIST(root=\"../data\", train=False, transform=transform, download=True)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Train dataset size: {len(mnist_train)}, Test dataset size: {len(mnist_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated 5 clients, each with 12000 training samples.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Define the number of clients and split sizes\n",
    "num_clients = 5\n",
    "client_data_size = len(mnist_train) // num_clients\n",
    "\n",
    "# Split the training data into smaller datasets for each client\n",
    "client_datasets = random_split(mnist_train, [client_data_size] * num_clients)\n",
    "\n",
    "# Create DataLoaders for each client\n",
    "client_loaders = [DataLoader(ds, batch_size=32, shuffle=True) for ds in client_datasets]\n",
    "\n",
    "# Test DataLoader for evaluation\n",
    "test_loader = DataLoader(mnist_test, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Simulated {num_clients} clients, each with {client_data_size} training samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12000, 12000, 12000, 12000, 12000]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[client_data_size] * num_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up and initialize the Global Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiate the global model (server)\n",
    "model = fl.create_model()\n",
    "global_model = model\n",
    "print(global_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a training loop that is run on a client for a number of epochs\n",
    "def train_client(model, dataloader, epochs=1):\n",
    "    # Create a copy of the global model\n",
    "    local_model = create_model()\n",
    "    local_model.load_state_dict(model.state_dict())\n",
    "    \n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(local_model.parameters(), lr=0.01)\n",
    "    \n",
    "    # Training loop\n",
    "    local_model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = local_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return local_model.state_dict()  # Return updated model parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Federated Learning Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Global model updated for round 1\n",
      "Round 2\n",
      "Global model updated for round 2\n",
      "Round 3\n",
      "Global model updated for round 3\n",
      "Round 4\n",
      "Global model updated for round 4\n"
     ]
    }
   ],
   "source": [
    "# This took me 2 mins to run\n",
    "# Simulate federated learning\n",
    "# A learning round consists of all clients training their local models and then aggregating the updates\n",
    "num_rounds = 4\n",
    "assert num_clients == len(client_loaders)\n",
    "\n",
    "# Here we conduct federated learning rounds\n",
    "for round_num in range(num_rounds):\n",
    "    print(f\"Round {round_num + 1}\")\n",
    "    \n",
    "    # Collect client updates\n",
    "    client_states = []\n",
    "    for client_loader in client_loaders:\n",
    "        client_state = train_client(global_model, client_loader, epochs=3)\n",
    "        client_states.append(client_state)\n",
    "    \n",
    "    # Aggregate updates using Federated Averaging\n",
    "    new_global_state = fl.federated_averaging(global_model, client_states)\n",
    "    global_model.load_state_dict(new_global_state)\n",
    "    \n",
    "    print(f\"Global model updated for round {round_num + 1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global model accuracy: 93.38%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f\"Global model accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "evaluate_model(global_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
